## ‚ö° NumPy - Performance Optimization

_Optymalizacja wydajno≈õci oblicze≈Ñ numerycznych w NumPy_

---

### üìù Wprowadzenie do optymalizacji NumPy

**Wydajno≈õƒá NumPy** zale≈ºy od kilku kluczowych czynnik√≥w:

1. **Vectorization** - wykorzystanie operacji na ca≈Çych tablicach
2. **Memory layout** - organizacja danych w pamiƒôci  
3. **Data types** - wyb√≥r odpowiednich typ√≥w danych
4. **Broadcasting** - efektywne operacje na r√≥≈ºnych rozmiarach
5. **Compiled libraries** - BLAS, LAPACK, MKL

---

### üöÄ Vectorization - unikanie pƒôtli Python

#### Problem z pƒôtlami Python

```python
import numpy as np
import time

# Por√≥wnanie wydajno≈õci: pƒôtla Python vs vectorization
def python_sum_of_squares(arr):
    """Suma kwadrat√≥w - wersja Python z pƒôtlƒÖ"""
    total = 0
    for i in range(len(arr)):
        total += arr[i] ** 2
    return total

def numpy_sum_of_squares(arr):
    """Suma kwadrat√≥w - wersja vectorized NumPy"""
    return np.sum(arr ** 2)

# Test wydajno≈õci
arr = np.random.rand(1000000)

# Python loop
start_time = time.time()
result_python = python_sum_of_squares(arr)
python_time = time.time() - start_time

# NumPy vectorized
start_time = time.time()
result_numpy = numpy_sum_of_squares(arr)
numpy_time = time.time() - start_time

print(f"Python loop: {python_time:.6f}s")
print(f"NumPy vectorized: {numpy_time:.6f}s")
print(f"Speedup: {python_time/numpy_time:.1f}x")
print(f"Results equal: {np.isclose(result_python, result_numpy)}")
```

#### Zamiana pƒôtli na operacje vectorized

```python
# ‚ùå Nieefektywne - pƒôtle Python
def distance_matrix_slow(points):
    """Macierz odleg≈Ço≈õci - wersja z pƒôtlami"""
    n = len(points)
    distances = np.zeros((n, n))
    
    for i in range(n):
        for j in range(n):
            distances[i, j] = np.sqrt(np.sum((points[i] - points[j]) ** 2))
    
    return distances

# ‚úÖ Efektywne - broadcasting i vectorization
def distance_matrix_fast(points):
    """Macierz odleg≈Ço≈õci - wersja vectorized"""
    points = np.array(points)
    # Broadcasting: (n, 1, d) - (1, n, d) = (n, n, d)
    diff = points[:, np.newaxis, :] - points[np.newaxis, :, :]
    # Sum along last axis and sqrt
    distances = np.sqrt(np.sum(diff ** 2, axis=2))
    return distances

# Test na przyk≈Çadowych punktach
points = np.random.rand(500, 3)  # 500 punkt√≥w w 3D

start_time = time.time()
dist_slow = distance_matrix_slow(points)
slow_time = time.time() - start_time

start_time = time.time()
dist_fast = distance_matrix_fast(points)
fast_time = time.time() - start_time

print(f"Slow version: {slow_time:.4f}s")
print(f"Fast version: {fast_time:.4f}s") 
print(f"Speedup: {slow_time/fast_time:.1f}x")
print(f"Results equal: {np.allclose(dist_slow, dist_fast)}")
```

---

### üß† Memory Layout i Cache Efficiency

#### Row-major vs Column-major

```python
# NumPy domy≈õlnie u≈ºywa row-major (C order)
arr_c = np.random.rand(1000, 1000)  # C order (row-major)
arr_f = np.random.rand(1000, 1000)  # Fortran order (column-major)
arr_f = np.asfortranarray(arr_f)

print(f"C-contiguous: {arr_c.flags.c_contiguous}")
print(f"F-contiguous: {arr_f.flags.f_contiguous}")

# Test wydajno≈õci dostƒôpu do element√≥w
def sum_rows(arr):
    """Sumowanie wierszami (cache-friendly dla C order)"""
    total = 0
    for i in range(arr.shape[0]):
        total += np.sum(arr[i, :])
    return total

def sum_cols(arr):
    """Sumowanie kolumnami (cache-friendly dla F order)"""
    total = 0
    for j in range(arr.shape[1]):
        total += np.sum(arr[:, j])
    return total

# Test dla C order
start_time = time.time()
sum_c_rows = sum_rows(arr_c)
c_rows_time = time.time() - start_time

start_time = time.time()
sum_c_cols = sum_cols(arr_c)
c_cols_time = time.time() - start_time

print(f"\nC order array:")
print(f"Summing by rows: {c_rows_time:.4f}s")
print(f"Summing by cols: {c_cols_time:.4f}s")
print(f"Row/Col ratio: {c_cols_time/c_rows_time:.2f}")

# Test dla F order  
start_time = time.time()
sum_f_rows = sum_rows(arr_f)
f_rows_time = time.time() - start_time

start_time = time.time()
sum_f_cols = sum_cols(arr_f)
f_cols_time = time.time() - start_time

print(f"\nF order array:")
print(f"Summing by rows: {f_rows_time:.4f}s")
print(f"Summing by cols: {f_cols_time:.4f}s")
print(f"Row/Col ratio: {f_rows_time/f_cols_time:.2f}")
```

#### Memory views vs copies

```python
# Views vs copies - wp≈Çyw na wydajno≈õƒá
large_array = np.random.rand(10000, 10000)

# View (no copying) - szybkie
start_time = time.time()
subarray_view = large_array[100:200, 100:200]  # View
view_time = time.time() - start_time

# Copy - wolniejsze
start_time = time.time()
subarray_copy = large_array[100:200, 100:200].copy()  # Explicit copy
copy_time = time.time() - start_time

print(f"View creation: {view_time:.6f}s")
print(f"Copy creation: {copy_time:.6f}s")

# Sprawdzenie czy to view czy copy
print(f"Is view: {np.shares_memory(large_array, subarray_view)}")
print(f"Is copy: {np.shares_memory(large_array, subarray_copy)}")

# Uwaga: niekt√≥re operacje mogƒÖ zmuszaƒá do kopii
non_contiguous = large_array[::2, ::2]  # Co drugi element
print(f"Non-contiguous is contiguous: {non_contiguous.flags.c_contiguous}")
```

---

### üî¢ Optymalizacja typ√≥w danych

#### Wyb√≥r w≈Ça≈õciwego dtype

```python
# Por√≥wnanie r√≥≈ºnych typ√≥w danych
sizes = [100, 1000, 10000]
dtypes = [np.int8, np.int32, np.int64, np.float32, np.float64]

for size in sizes:
    print(f"\nArray size: {size} x {size}")
    print("=" * 40)
    
    for dtype in dtypes:
        # Tworzenie tablicy
        arr = np.random.randint(0, 100, size=(size, size)).astype(dtype)
        
        # Pamiƒôƒá
        memory_mb = arr.nbytes / (1024 * 1024)
        
        # Test operacji matematycznej
        start_time = time.time()
        result = np.sum(arr ** 2)
        operation_time = time.time() - start_time
        
        print(f"{dtype.__name__:>8}: {memory_mb:6.2f} MB, {operation_time:.6f}s")

# Przyk≈Çad: kiedy u≈ºyƒá mniejszego typu
def process_image_data():
    """Przetwarzanie danych obrazu - uint8 vs float64"""
    
    # Symulacja danych obrazu (0-255)
    image_uint8 = np.random.randint(0, 256, size=(1000, 1000, 3), dtype=np.uint8)
    image_float64 = image_uint8.astype(np.float64) / 255.0
    
    print(f"uint8 size: {image_uint8.nbytes / 1024 / 1024:.2f} MB")
    print(f"float64 size: {image_float64.nbytes / 1024 / 1024:.2f} MB")
    print(f"Memory ratio: {image_float64.nbytes / image_uint8.nbytes:.1f}x")
    
    # Operacja na ka≈ºdym typie
    start_time = time.time()
    mean_uint8 = np.mean(image_uint8, axis=2)
    uint8_time = time.time() - start_time
    
    start_time = time.time()
    mean_float64 = np.mean(image_float64, axis=2)
    float64_time = time.time() - start_time
    
    print(f"uint8 operation: {uint8_time:.6f}s")
    print(f"float64 operation: {float64_time:.6f}s")

process_image_data()
```

---

### üì° Broadcasting i Memory-Efficient Operations

#### Zrozumienie broadcasting rules

```python
# Broadcasting rules i wydajno≈õƒá
def demonstrate_broadcasting():
    """Demonstracja efektywnego broadcasting"""
    
    # Du≈ºe tablice
    large_matrix = np.random.rand(1000, 2000)
    row_vector = np.random.rand(1, 2000)
    col_vector = np.random.rand(1000, 1)
    scalar = 5.0
    
    print("Memory usage:")
    print(f"Large matrix: {large_matrix.nbytes / 1024 / 1024:.2f} MB")
    print(f"Row vector: {row_vector.nbytes / 1024:.2f} KB")
    print(f"Col vector: {col_vector.nbytes / 1024:.2f} KB")
    
    # ‚úÖ Efektywne broadcasting - nie tworzy kopii
    start_time = time.time()
    result1 = large_matrix + row_vector  # Broadcasting
    broadcast_time = time.time() - start_time
    
    # ‚ùå Nieefektywne - explicit tiling tworzy kopie
    start_time = time.time()
    row_tiled = np.tile(row_vector, (1000, 1))  # Tworzy du≈ºƒÖ kopiƒô!
    result2 = large_matrix + row_tiled
    tiling_time = time.time() - start_time
    
    print(f"\nBroadcasting time: {broadcast_time:.6f}s")
    print(f"Tiling time: {tiling_time:.6f}s")
    print(f"Results equal: {np.allclose(result1, result2)}")
    
    # Complex broadcasting example
    start_time = time.time()
    # (1000, 2000) + (1, 2000) + (1000, 1) + scalar
    complex_result = large_matrix + row_vector + col_vector + scalar
    complex_time = time.time() - start_time
    
    print(f"Complex broadcasting: {complex_time:.6f}s")

demonstrate_broadcasting()
```

#### Operacje in-place dla oszczƒôdno≈õci pamiƒôci

```python
# In-place operations - modyfikacja bez kopii
def compare_inplace_operations():
    """Por√≥wnanie operacji in-place vs tworzenie nowych tablic"""
    
    # Du≈ºa tablica
    size = 5000
    arr = np.random.rand(size, size)
    original_id = id(arr)
    
    print(f"Original array memory: {arr.nbytes / 1024 / 1024:.2f} MB")
    
    # ‚ùå Nieefektywne - tworzy nowƒÖ tablicƒô
    start_time = time.time()
    arr_new = arr * 2 + 1
    new_array_time = time.time() - start_time
    
    # ‚úÖ Efektywne - in-place modification
    start_time = time.time()
    arr *= 2
    arr += 1
    inplace_time = time.time() - start_time
    
    print(f"\nNew array creation: {new_array_time:.6f}s")
    print(f"In-place operations: {inplace_time:.6f}s")
    print(f"Speedup: {new_array_time/inplace_time:.1f}x")
    print(f"Same memory location: {id(arr) == original_id}")
    
    # Universal functions z out parameter
    arr1 = np.random.rand(1000, 1000)
    arr2 = np.random.rand(1000, 1000)
    result = np.empty_like(arr1)  # Pre-allocate
    
    start_time = time.time()
    np.add(arr1, arr2, out=result)  # In-place w result
    out_param_time = time.time() - start_time
    
    start_time = time.time()
    normal_result = arr1 + arr2  # Tworzy nowƒÖ tablicƒô
    normal_time = time.time() - start_time
    
    print(f"\nWith out parameter: {out_param_time:.6f}s")
    print(f"Normal addition: {normal_time:.6f}s")

compare_inplace_operations()
```

---

### üîß Compiled Libraries Integration

#### Wykorzystanie MKL i BLAS

```python
# Sprawdzanie konfiguracji bibliotek
def check_numpy_config():
    """Sprawdzenie konfiguracji NumPy i dostƒôpnych bibliotek"""
    
    print("NumPy configuration:")
    print("=" * 50)
    
    # Podstawowe informacje
    print(f"NumPy version: {np.__version__}")
    
    # Sprawdzenie BLAS/LAPACK
    try:
        config = np.__config__.show()
        print("\nBLAS/LAPACK configuration available")
    except:
        print("\nBLAS/LAPACK configuration not available")
    
    # Test wydajno≈õci du≈ºych operacji macierzowych
    sizes = [500, 1000, 2000]
    
    for size in sizes:
        print(f"\nMatrix multiplication {size}x{size}:")
        A = np.random.rand(size, size)
        B = np.random.rand(size, size)
        
        start_time = time.time()
        C = A @ B
        elapsed = time.time() - start_time
        
        # FLOPS estimation (2*n^3 operations)
        flops = 2 * size**3
        gflops = flops / elapsed / 1e9
        
        print(f"  Time: {elapsed:.4f}s")
        print(f"  Performance: {gflops:.2f} GFLOPS")

check_numpy_config()

# Wykorzystanie numexpr dla z≈Ço≈ºonych wyra≈ºe≈Ñ
try:
    import numexpr as ne
    
    def compare_numexpr():
        """Por√≥wnanie NumPy vs numexpr"""
        size = 1000000
        a = np.random.rand(size)
        b = np.random.rand(size)
        c = np.random.rand(size)
        
        # NumPy
        start_time = time.time()
        result_numpy = 2*a + 3*b + 4*c
        numpy_time = time.time() - start_time
        
        # numexpr
        start_time = time.time()
        result_numexpr = ne.evaluate("2*a + 3*b + 4*c")
        numexpr_time = time.time() - start_time
        
        print(f"\nNumExpr comparison:")
        print(f"NumPy: {numpy_time:.6f}s")
        print(f"NumExpr: {numexpr_time:.6f}s")
        print(f"Speedup: {numpy_time/numexpr_time:.1f}x")
        print(f"Results equal: {np.allclose(result_numpy, result_numexpr)}")
    
    compare_numexpr()
    
except ImportError:
    print("NumExpr not available - install with: pip install numexpr")
```

---

### ‚ö° Specific Optimization Techniques

#### Optimizing array creation

```python
def optimize_array_creation():
    """Optymalizacja tworzenia tablic"""
    
    size = 1000000
    
    # Pre-allocation vs dynamic growth
    print("Array creation comparison:")
    
    # ‚ùå Bardzo wolne - dynamiczne rozszerzanie
    start_time = time.time()
    slow_array = np.array([])
    for i in range(1000):  # Mniejszy rozmiar dla demonstracji
        slow_array = np.append(slow_array, i)
    slow_time = time.time() - start_time
    
    # ‚úÖ Szybkie - pre-allocation
    start_time = time.time()
    fast_array = np.zeros(1000)
    for i in range(1000):
        fast_array[i] = i
    fast_time = time.time() - start_time
    
    # ‚úÖ Najszybsze - vectorized
    start_time = time.time()
    fastest_array = np.arange(1000)
    fastest_time = time.time() - start_time
    
    print(f"Dynamic append: {slow_time:.6f}s")
    print(f"Pre-allocated: {fast_time:.6f}s")
    print(f"Vectorized: {fastest_time:.6f}s")
    
    # Specialized creation functions
    print(f"\nSpecialized creation functions:")
    
    # zeros vs empty
    start_time = time.time()
    zeros_array = np.zeros((size,))
    zeros_time = time.time() - start_time
    
    start_time = time.time()
    empty_array = np.empty((size,))
    empty_array.fill(0)  # Manual fill
    empty_time = time.time() - start_time
    
    print(f"np.zeros: {zeros_time:.6f}s")
    print(f"np.empty + fill: {empty_time:.6f}s")

optimize_array_creation()
```

#### Memory pool and object reuse

```python
class ArrayPool:
    """Prosty pool tablic do wielokrotnego u≈ºytku"""
    
    def __init__(self):
        self.pool = {}
    
    def get_array(self, shape, dtype=np.float64):
        """Pobierz tablicƒô z pool lub utw√≥rz nowƒÖ"""
        key = (shape, dtype)
        if key in self.pool and len(self.pool[key]) > 0:
            return self.pool[key].pop()
        else:
            return np.empty(shape, dtype=dtype)
    
    def return_array(self, arr):
        """Zwr√≥ƒá tablicƒô do pool"""
        key = (arr.shape, arr.dtype)
        if key not in self.pool:
            self.pool[key] = []
        self.pool[key].append(arr)
    
    def clear(self):
        """Wyczy≈õƒá pool"""
        self.pool.clear()

def test_array_pool():
    """Test wydajno≈õci array pool"""
    pool = ArrayPool()
    shape = (1000, 1000)
    n_iterations = 100
    
    # Bez pool - ka≈ºda iteracja tworzy nowƒÖ tablicƒô
    start_time = time.time()
    for _ in range(n_iterations):
        arr = np.empty(shape)
        # Symulacja obr√≥bki
        arr.fill(1.0)
        result = np.sum(arr)
    no_pool_time = time.time() - start_time
    
    # Z pool - reuse tablic
    start_time = time.time()
    for _ in range(n_iterations):
        arr = pool.get_array(shape)
        # Symulacja obr√≥bki
        arr.fill(1.0)
        result = np.sum(arr)
        pool.return_array(arr)
    with_pool_time = time.time() - start_time
    
    print(f"Without pool: {no_pool_time:.6f}s")
    print(f"With pool: {with_pool_time:.6f}s")
    print(f"Improvement: {no_pool_time/with_pool_time:.1f}x")

test_array_pool()
```

---

### üîç Profiling i Diagnostyka

#### Memory profiling

```python
import psutil
import os

def memory_usage():
    """Sprawdzenie u≈ºycia pamiƒôci przez proces"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024  # MB

def profile_memory_usage():
    """Profilowanie u≈ºycia pamiƒôci"""
    
    print("Memory profiling:")
    print(f"Initial memory: {memory_usage():.2f} MB")
    
    # Tworzenie du≈ºej tablicy
    large_array = np.random.rand(10000, 1000)
    print(f"After large array creation: {memory_usage():.2f} MB")
    
    # Operacja tworzƒÖca kopiƒô
    copied_array = large_array * 2
    print(f"After copy creation: {memory_usage():.2f} MB")
    
    # Usuniƒôcie kopii
    del copied_array
    print(f"After copy deletion: {memory_usage():.2f} MB")
    
    # In-place operation
    large_array *= 3
    print(f"After in-place operation: {memory_usage():.2f} MB")
    
    # Final cleanup
    del large_array
    print(f"After cleanup: {memory_usage():.2f} MB")

profile_memory_usage()

# Timing utilities
def time_function(func, *args, n_runs=5, **kwargs):
    """Zmierz czas wykonania funkcji z wieloma uruchomieniami"""
    times = []
    
    for _ in range(n_runs):
        start_time = time.perf_counter()
        result = func(*args, **kwargs)
        end_time = time.perf_counter()
        times.append(end_time - start_time)
    
    times = np.array(times)
    print(f"Function: {func.__name__}")
    print(f"Mean time: {np.mean(times):.6f}s ¬± {np.std(times):.6f}s")
    print(f"Min time: {np.min(times):.6f}s")
    print(f"Max time: {np.max(times):.6f}s")
    
    return result, times

# Przyk≈Çad u≈ºycia
def test_function(size):
    arr = np.random.rand(size, size)
    return np.linalg.eigvals(arr)

result, times = time_function(test_function, 500, n_runs=3)
```

---

### üìä Konkretne przypadki optymalizacji

#### Optymalizacja operacji na du≈ºych danych

```python
def optimize_large_data_processing():
    """Optymalizacja przetwarzania du≈ºych zbior√≥w danych"""
    
    # Symulacja du≈ºego datasetu
    n_samples = 1000000
    n_features = 100
    
    # ‚ùå Nieefektywne podej≈õcie
    def slow_processing(data):
        result = []
        for i in range(data.shape[0]):
            row_sum = np.sum(data[i, :])
            row_mean = np.mean(data[i, :])
            row_std = np.std(data[i, :])
            result.append([row_sum, row_mean, row_std])
        return np.array(result)
    
    # ‚úÖ Efektywne podej≈õcie vectorized
    def fast_processing(data):
        row_sums = np.sum(data, axis=1)
        row_means = np.mean(data, axis=1) 
        row_stds = np.std(data, axis=1)
        return np.column_stack([row_sums, row_means, row_stds])
    
    # ‚úÖ Jeszcze bardziej efektywne - chunk processing
    def chunked_processing(data, chunk_size=10000):
        n_samples = data.shape[0]
        results = []
        
        for start_idx in range(0, n_samples, chunk_size):
            end_idx = min(start_idx + chunk_size, n_samples)
            chunk = data[start_idx:end_idx]
            
            chunk_result = fast_processing(chunk)
            results.append(chunk_result)
        
        return np.vstack(results)
    
    # Generowanie danych testowych (mniejszych dla demonstracji)
    test_data = np.random.rand(10000, n_features)
    
    # Por√≥wnanie czas√≥w
    print("Large data processing comparison:")
    
    start_time = time.time()
    result_slow = slow_processing(test_data[:1000])  # Mniejszy sample
    slow_time = time.time() - start_time
    
    start_time = time.time()
    result_fast = fast_processing(test_data)
    fast_time = time.time() - start_time
    
    start_time = time.time()
    result_chunked = chunked_processing(test_data, chunk_size=2000)
    chunked_time = time.time() - start_time
    
    print(f"Slow (loop): {slow_time:.6f}s")
    print(f"Fast (vectorized): {fast_time:.6f}s")
    print(f"Chunked: {chunked_time:.6f}s")

optimize_large_data_processing()
```

---

### üí° Best Practices Summary

#### Checklist optymalizacji NumPy

```python
def numpy_optimization_checklist():
    """
    Lista kontrolna do optymalizacji kodu NumPy:
    """
    
    checklist = """
    ‚úÖ VECTORIZATION:
    - ZastƒÖp pƒôtle Python operacjami na tablicach
    - U≈ºyj broadcasting zamiast jawnego kopiowania
    - Wykorzystaj universal functions (ufuncs)
    
    ‚úÖ MEMORY MANAGEMENT:
    - Pre-alokuj tablice gdy znasz rozmiar
    - U≈ºywaj in-place operations gdzie mo≈ºliwe
    - Wybieraj odpowiedni dtype (nie zawsze float64)
    - Unikaj niepotrzebnych kopii (sprawdzaj views vs copies)
    
    ‚úÖ CACHE EFFICIENCY:
    - Respektuj memory layout (C vs Fortran order)
    - Przetwarzaj dane w spos√≥b sekwencyjny
    - U≈ºywaj contiguous arrays
    
    ‚úÖ ALGORITHM SELECTION:
    - Wybierz specialized functions dla konkretnych zada≈Ñ
    - Wykorzystuj optimized linear algebra (BLAS/LAPACK)
    - Rozwa≈º chunk processing dla bardzo du≈ºych danych
    
    ‚úÖ PROFILING:
    - Mierz wydajno≈õƒá przed optymalizacjƒÖ
    - Identyfikuj bottlenecks
    - Sprawdzaj u≈ºycie pamiƒôci
    """
    
    print(checklist)

numpy_optimization_checklist()
```

#### Przyk≈Çad kompleksowej optymalizacji

```python
class OptimizedDataProcessor:
    """Przyk≈Çad klasy z zoptymalizowanym przetwarzaniem danych"""
    
    def __init__(self, chunk_size=50000):
        self.chunk_size = chunk_size
        self.array_pool = {}
    
    def _get_temp_array(self, shape, dtype):
        """Pobierz tablicƒô tymczasowƒÖ z pool"""
        key = (shape, dtype)
        if key in self.array_pool:
            return self.array_pool[key]
        else:
            arr = np.empty(shape, dtype=dtype)
            self.array_pool[key] = arr
            return arr
    
    def normalize_features(self, data):
        """Znormalizuj cechy - zoptymalizowana wersja"""
        # Pre-compute statistics
        means = np.mean(data, axis=0, keepdims=True)
        stds = np.std(data, axis=0, keepdims=True)
        
        # Avoid division by zero
        stds[stds == 0] = 1
        
        # In-place normalization
        data -= means
        data /= stds
        
        return data
    
    def compute_distances_chunked(self, points1, points2):
        """Oblicz macierz odleg≈Ço≈õci w chunks"""
        n1, n2 = len(points1), len(points2)
        distances = np.empty((n1, n2), dtype=np.float32)  # Use float32 for memory
        
        # Process in chunks to manage memory
        for i in range(0, n1, self.chunk_size):
            end_i = min(i + self.chunk_size, n1)
            chunk1 = points1[i:end_i]
            
            for j in range(0, n2, self.chunk_size):
                end_j = min(j + self.chunk_size, n2)
                chunk2 = points2[j:end_j]
                
                # Compute distances for this chunk
                diff = chunk1[:, np.newaxis, :] - chunk2[np.newaxis, :, :]
                chunk_distances = np.sqrt(np.sum(diff**2, axis=2))
                
                distances[i:end_i, j:end_j] = chunk_distances
        
        return distances
    
    def process_dataset(self, data):
        """Kompleksowe przetwarzanie datasetu"""
        print(f"Processing dataset shape: {data.shape}")
        print(f"Memory usage: {data.nbytes / 1024 / 1024:.2f} MB")
        
        start_time = time.time()
        
        # 1. Normalizacja
        normalized_data = self.normalize_features(data.copy())
        
        # 2. Compute some statistics efficiently
        feature_stats = {
            'means': np.mean(normalized_data, axis=0),
            'stds': np.std(normalized_data, axis=0),
            'correlations': np.corrcoef(normalized_data.T)
        }
        
        total_time = time.time() - start_time
        print(f"Processing completed in {total_time:.4f}s")
        
        return normalized_data, feature_stats

# Test zoptymalizowanego processora
processor = OptimizedDataProcessor(chunk_size=10000)
test_data = np.random.rand(50000, 20)

processed_data, stats = processor.process_dataset(test_data)
print(f"Processed data shape: {processed_data.shape}")
print(f"Feature means range: [{np.min(stats['means']):.6f}, {np.max(stats['means']):.6f}]")
```

---

### üîó PowiƒÖzane tematy

- [[NumPy - Podstawy]] - Podstawowe operacje NumPy
- [[NumPy - Memory Management i Broadcasting]] - ZarzƒÖdzanie pamiƒôciƒÖ
- [[Machine Learning Pipeline - Preprocessing]] - Zastosowanie w ML
- [[Pandas - Performance Optimization]] - Optymalizacja Pandas